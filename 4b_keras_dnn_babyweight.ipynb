{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4b_keras_dnn_babyweight.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtrbx+/gKyDOnKHnsMsNEl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canislatranscoxus/gcp_ml_certification/blob/master/4b_keras_dnn_babyweight.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu3WG_Sf5Ieo"
      },
      "source": [
        "\n",
        "# Keras dnn Babyweight\n",
        "Canis notes.\n",
        "\n",
        "In this notebook we load our CSV dataset of mothers and we want to predict baby weigth before birth.\n",
        "\n",
        "My practice using  `4b_keras_dnn_babyweight.ipynb`\n",
        "as reference\n",
        "\n",
        "https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/structured/solutions/4b_keras_dnn_babyweight.ipynb\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuUIbuK66GiG"
      },
      "source": [
        "### load needed libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi2HxlkW52_3",
        "outputId": "8ee2091a-08c7-4ad2-dccc-de9e9988372f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "print( 'tensorflow version: {} '.format( tf.__version__ ) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version: 2.3.0 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD79Bjd-65N5"
      },
      "source": [
        "### load CSV funtion\n",
        "\n",
        "* train.csv\n",
        "* eval.csv\n",
        "* test.csv\n",
        "\n",
        "these files were created in 4a_sample_babyweight\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R7Oo1Rz6KMc"
      },
      "source": [
        "# this is what we want to predict\n",
        "LABEL_COLUMN = \"weight_pounds\"\n",
        "\n",
        "CSV_COLUMNS = [ \"weight_pounds\", \"is_male\", \"mother_age\", \"plurality\", \"gestation_weeks\"]\n",
        "DEFAULTS    = [ [0.0]          , [\"null\"] , [0.0]       , [\"null\"]   , [0.0]            ]\n",
        "               "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdookd6CgMZa"
      },
      "source": [
        "def features_and_labels(row_data):\n",
        "    \"\"\"Splits features and labels from feature dictionary.\n",
        "\n",
        "    Args:\n",
        "        row_data: Dictionary of CSV column names and tensor values.\n",
        "    Returns:\n",
        "        Dictionary of feature tensors and label tensor.\n",
        "    \"\"\"\n",
        "    label = row_data.pop(LABEL_COLUMN)\n",
        "    return row_data, label  # features, label\n",
        "\n",
        "\n",
        "def load_dataset(pattern, batch_size=1, mode='eval'):\n",
        "    \"\"\"Loads dataset using the tf.data API from CSV files.\n",
        "\n",
        "    Args:\n",
        "        pattern: str, file pattern to glob into list of files.\n",
        "        batch_size: int, the number of examples per batch.\n",
        "        mode: 'train' | 'eval' to determine if training or evaluating.\n",
        "    Returns:\n",
        "        `Dataset` object.\n",
        "    \"\"\"\n",
        "    # Make a CSV dataset\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        file_pattern    = pattern,\n",
        "        batch_size      = batch_size,\n",
        "        column_names    = CSV_COLUMNS,\n",
        "        column_defaults = DEFAULTS)\n",
        "\n",
        "    # Map dataset to features and label\n",
        "    dataset = dataset.map(map_func=features_and_labels)  # features, label\n",
        "\n",
        "    # Shuffle and repeat for training\n",
        "    if mode == 'train':\n",
        "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
        "\n",
        "    # Take advantage of multi-threading; 1=AUTOTUNE\n",
        "    dataset = dataset.prefetch(buffer_size=1)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgYJnFcydspk"
      },
      "source": [
        "### functions needed for Model \n",
        "\n",
        "here we declare some functions:\n",
        "\n",
        "* categorical_fc()\n",
        "* get_model_outputs()\n",
        "* create_input_layers()\n",
        "* create_feature_columns()\n",
        "* rmse()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nO9Lpw_S3bn4"
      },
      "source": [
        "### Features in the Model.\n",
        "\n",
        "Features are numeric columns that can be used in the model.\n",
        "\n",
        "the most used are:\n",
        "\n",
        "* Numeric Column     --> numeric_column\n",
        "\n",
        "* Categorical Column (one hot encoding) -->   \n",
        "    * categorical_column_with_vocabulary_list\n",
        "    * indicator_column\n",
        "\n",
        "* Categorical Column --> \n",
        "    * categorical_column_with_vocabulary_list\n",
        "    * embedding_column\n",
        "\n",
        "* bucketized_column (numeric ) --> \n",
        "    * numeric_column\n",
        "    * bucketized_column\n",
        "\n",
        "* Crossed features --> crossed_column\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "There are many, look here\n",
        "https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_JJzyat3cgv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5frSaF0ExHK"
      },
      "source": [
        "def create_input_layers():\n",
        "    \"\"\"Creates dictionary of input layers for each feature.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of `tf.Keras.layers.Input` layers for each feature.\n",
        "    \"\"\"\n",
        "    inputs = {\n",
        "        colname: tf.keras.layers.Input(\n",
        "            name=colname, shape=(), dtype=\"float32\")\n",
        "        for colname in [\"mother_age\", \"gestation_weeks\"]}\n",
        "\n",
        "    inputs.update({\n",
        "        colname: tf.keras.layers.Input(\n",
        "            name=colname, shape=(), dtype=\"string\")\n",
        "        for colname in [\"is_male\", \"plurality\"]})\n",
        "\n",
        "    return inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxWN_3v0imdJ"
      },
      "source": [
        "def categorical_fc(name, values):\n",
        "    \"\"\"Helper function to wrap categorical feature by indicator column.\n",
        "\n",
        "    Args:\n",
        "        name: str, name of feature.\n",
        "        values: list, list of strings of categorical values.\n",
        "    Returns:\n",
        "        Indicator column of categorical feature.\n",
        "    \"\"\"\n",
        "    cat_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "            key=name, vocabulary_list=values)\n",
        "\n",
        "    return tf.feature_column.indicator_column(categorical_column=cat_column)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC41q8YHi8id"
      },
      "source": [
        "def create_feature_columns():\n",
        "    \"\"\"Creates dictionary of feature columns from inputs.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of feature columns.\n",
        "    \"\"\"\n",
        "    feature_columns = {\n",
        "        colname : tf.feature_column.numeric_column(key=colname)\n",
        "           for colname in [\"mother_age\", \"gestation_weeks\"]\n",
        "    }\n",
        "\n",
        "    feature_columns[\"is_male\"] = categorical_fc(\n",
        "        \"is_male\", [\"True\", \"False\", \"Unknown\"])\n",
        "    \n",
        "    feature_columns[\"plurality\"] = categorical_fc(\n",
        "        \"plurality\", [\"Single(1)\", \"Twins(2)\", \"Triplets(3)\", \"Quadruplets(4)\", \"Quintuplets(5)\", \"Multiple(2+)\"])\n",
        "\n",
        "    return feature_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQL7TQJErO4r"
      },
      "source": [
        "### create DNN hidden layers and output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ps3wa_Li8vN"
      },
      "source": [
        "def get_model_outputs(inputs):\n",
        "    \"\"\"Creates model architecture and returns outputs.\n",
        "\n",
        "    Args:\n",
        "        inputs: Dense tensor used as inputs to model.\n",
        "    Returns:\n",
        "        Dense tensor output from the model.\n",
        "    \"\"\"\n",
        "    # Create two hidden layers of [64, 32] just in like the BQML DNN\n",
        "    h1 = tf.keras.layers.Dense(64, activation=\"relu\", name=\"h1\")( inputs)\n",
        "    h2 = tf.keras.layers.Dense(32, activation=\"relu\", name=\"h2\")( h1    )\n",
        "\n",
        "    # Final output is a linear activation because this is regression\n",
        "    output = tf.keras.layers.Dense(\n",
        "        units=1, activation=\"linear\", name=\"weight\")( h2 )\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7Oac5fvrjZ6"
      },
      "source": [
        "### evaluation metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5hQPH3Ti8PU"
      },
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    \"\"\"Calculates RMSE evaluation metric.\n",
        "\n",
        "    Args:\n",
        "        y_true: tensor, true labels.\n",
        "        y_pred: tensor, predicted labels.\n",
        "    Returns:\n",
        "        Tensor with value of RMSE between true and predicted labels.\n",
        "    \"\"\"\n",
        "    return tf.sqrt(tf.reduce_mean((y_pred - y_true) ** 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrWVQHVsEVoI"
      },
      "source": [
        "### The Deep Neural Network Model\n",
        "\n",
        "will have this Architecture\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N04AjhYzrtx5",
        "outputId": "38a1b719-994f-4850-9404-5b4c398cfc07"
      },
      "source": [
        "def build_dnn_model():\n",
        "    \"\"\"Builds simple DNN using Keras Functional API.\n",
        "\n",
        "    Returns:\n",
        "        `tf.keras.models.Model` object.\n",
        "    \"\"\"\n",
        "    # Create input layer\n",
        "    inputs = create_input_layers()\n",
        "\n",
        "    # Create feature columns\n",
        "    feature_columns = create_feature_columns()\n",
        "\n",
        "    # The constructor for DenseFeatures takes a list of numeric columns\n",
        "    # The Functional API in Keras requires: LayerConstructor()(inputs)\n",
        "    dnn_inputs = tf.keras.layers.DenseFeatures(\n",
        "        feature_columns=feature_columns.values())(inputs)\n",
        "\n",
        "    # Get output of model given inputs\n",
        "    output = get_model_outputs(dnn_inputs)\n",
        "\n",
        "    # Build model and compile it all together\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
        "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"Here is our DNN architecture so far:\\n\")\n",
        "model = build_dnn_model()\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here is our DNN architecture so far:\n",
            "\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "gestation_weeks (InputLayer)    [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "is_male (InputLayer)            [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "mother_age (InputLayer)         [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "plurality (InputLayer)          [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_features (DenseFeatures)  (None, 11)           0           gestation_weeks[0][0]            \n",
            "                                                                 is_male[0][0]                    \n",
            "                                                                 mother_age[0][0]                 \n",
            "                                                                 plurality[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "h1 (Dense)                      (None, 64)           768         dense_features[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "h2 (Dense)                      (None, 32)           2080        h1[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "weight (Dense)                  (None, 1)            33          h2[0][0]                         \n",
            "==================================================================================================\n",
            "Total params: 2,881\n",
            "Trainable params: 2,881\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYn_dRRGGB_6",
        "outputId": "7be5e513-f22c-441c-87eb-df6f2424d4ba"
      },
      "source": [
        "pip install graphviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb58kZCBHnzf"
      },
      "source": [
        "from graphviz import Digraph\n",
        "\n",
        "g = Digraph()\n",
        "# Add nodes 1 and 2\n",
        "\n",
        "with g.subgraph(name='cluster_input_layer') as c:\n",
        "  c.attr(style='filled', color='pink', rankdir='TB')\n",
        "  c.attr(label='input layer')\n",
        "  c.node_attr.update(style='filled', color='magenta')\n",
        "  \n",
        "  for column in CSV_COLUMNS:\n",
        "    if column == \"weight_pounds\":\n",
        "      continue\n",
        "    c.node( column  )\n",
        "\n",
        "with g.subgraph(name='cluster_dense_layer') as c:\n",
        "  c.attr(style='filled', color='blue', rankdir='TB')\n",
        "  c.node( 'dense_features'  ,color='cyan', style='filled', fillcolor='cyan'    )\n",
        "  c.edge( 'is_male'         , 'dense_features', constraint='false')\n",
        "  c.edge( 'mother_age'      , 'dense_features', constraint='false')\n",
        "  c.edge( 'plurality'       , 'dense_features', constraint='false')\n",
        "  c.edge( 'gestation_weeks' , 'dense_features', constraint='false')\n",
        "\n",
        "with g.subgraph(name='cluster_hiden_1') as c:\n",
        "  c.attr(style='filled', color='gold', rankdir='TB')\n",
        "  c.attr(label='hiden layer 1. 64 neurons')\n",
        "  c.node( 'h1'    ,color='yellow', style='filled', fillcolor='yellow'    )\n",
        "\n",
        "with g.subgraph(name='cluster_hiden_2') as c:\n",
        "  c.attr(style='filled', color='gold2', rankdir='TB')\n",
        "  c.attr(label='hiden layer 2. 32 neurons')\n",
        "  c.node( 'h2'    ,color='yellow', style='filled', fillcolor='yellow'    )\n",
        "\n",
        "\n",
        "g.node( 'weight', color='green', style='filled', fillcolor='green'   )\n",
        "\n",
        "g.edge( 'dense_features', 'h1'     , constraint='false' )\n",
        "g.edge( 'h1'            , 'h2'     , constraint='false' )\n",
        "g.edge( 'h2'            , 'weight' , constraint='false' )\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWXeBxfgdAsV"
      },
      "source": [
        "### Deep Neural Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "2byIQjWQdKY_",
        "outputId": "fca51acb-5cf6-43bd-e0f0-f5877ecf9c84"
      },
      "source": [
        "g"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fa1f3d1f860>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"1079pt\" height=\"126pt\"\n viewBox=\"0.00 0.00 1079.40 125.62\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 121.6173)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-121.6173 1075.3968,-121.6173 1075.3968,4 -4,4\"/>\n<g id=\"clust1\" class=\"cluster\">\n<title>cluster_input_layer</title>\n<polygon fill=\"#ffc0cb\" stroke=\"#ffc0cb\" points=\"8,-8 8,-83 493,-83 493,-8 8,-8\"/>\n<text text-anchor=\"middle\" x=\"250.5\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input layer</text>\n</g>\n<g id=\"clust2\" class=\"cluster\">\n<title>cluster_dense_layer</title>\n<polygon fill=\"#0000ff\" stroke=\"#0000ff\" points=\"501,-8 501,-60 647,-60 647,-8 501,-8\"/>\n</g>\n<g id=\"clust3\" class=\"cluster\">\n<title>cluster_hiden_1</title>\n<polygon fill=\"#ffd700\" stroke=\"#ffd700\" points=\"655,-8 655,-83 819,-83 819,-8 655,-8\"/>\n<text text-anchor=\"middle\" x=\"737\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hiden layer 1. 64 neurons</text>\n</g>\n<g id=\"clust4\" class=\"cluster\">\n<title>cluster_hiden_2</title>\n<polygon fill=\"#eec900\" stroke=\"#eec900\" points=\"827,-8 827,-83 991,-83 991,-8 827,-8\"/>\n<text text-anchor=\"middle\" x=\"909\" y=\"-67.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">hiden layer 2. 32 neurons</text>\n</g>\n<!-- is_male -->\n<g id=\"node1\" class=\"node\">\n<title>is_male</title>\n<ellipse fill=\"#ff00ff\" stroke=\"#ff00ff\" cx=\"446\" cy=\"-34\" rx=\"38.9931\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"446\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">is_male</text>\n</g>\n<!-- dense_features -->\n<g id=\"node5\" class=\"node\">\n<title>dense_features</title>\n<ellipse fill=\"#00ffff\" stroke=\"#00ffff\" cx=\"574\" cy=\"-34\" rx=\"64.9885\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"574\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">dense_features</text>\n</g>\n<!-- is_male&#45;&gt;dense_features -->\n<g id=\"edge1\" class=\"edge\">\n<title>is_male&#45;&gt;dense_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M485,-34C489.6227,-34 494.2455,-34 498.8682,-34\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"498.9883,-37.5001 508.9883,-34 498.9882,-30.5001 498.9883,-37.5001\"/>\n</g>\n<!-- mother_age -->\n<g id=\"node2\" class=\"node\">\n<title>mother_age</title>\n<ellipse fill=\"#ff00ff\" stroke=\"#ff00ff\" cx=\"334\" cy=\"-34\" rx=\"54.6905\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"334\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">mother_age</text>\n</g>\n<!-- mother_age&#45;&gt;dense_features -->\n<g id=\"edge2\" class=\"edge\">\n<title>mother_age&#45;&gt;dense_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M346.7679,-51.603C359.8012,-67.9284 381.6722,-91.1388 407,-101 440.547,-114.0612 453.9533,-112.697 488,-101 512.3047,-92.6499 535.0206,-74.3092 550.9958,-58.9247\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"553.6646,-61.2062 558.2741,-51.6666 548.7217,-56.2496 553.6646,-61.2062\"/>\n</g>\n<!-- plurality -->\n<g id=\"node3\" class=\"node\">\n<title>plurality</title>\n<ellipse fill=\"#ff00ff\" stroke=\"#ff00ff\" cx=\"219\" cy=\"-34\" rx=\"42.4939\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"219\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">plurality</text>\n</g>\n<!-- plurality&#45;&gt;dense_features -->\n<g id=\"edge3\" class=\"edge\">\n<title>plurality&#45;&gt;dense_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M228.9375,-51.8229C239.1223,-68.065 256.6183,-90.9988 279,-101 321.4035,-119.948 444.0755,-116.0906 488,-101 512.3047,-92.6499 535.0206,-74.3092 550.9958,-58.9247\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"553.6646,-61.2062 558.2741,-51.6666 548.7217,-56.2496 553.6646,-61.2062\"/>\n</g>\n<!-- gestation_weeks -->\n<g id=\"node4\" class=\"node\">\n<title>gestation_weeks</title>\n<ellipse fill=\"#ff00ff\" stroke=\"#ff00ff\" cx=\"87\" cy=\"-34\" rx=\"71.4873\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"87\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gestation_weeks</text>\n</g>\n<!-- gestation_weeks&#45;&gt;dense_features -->\n<g id=\"edge4\" class=\"edge\">\n<title>gestation_weeks&#45;&gt;dense_features</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M103.6253,-51.6824C120.3493,-68.0666 147.7848,-91.3194 177,-101 242.6034,-122.7379 422.6387,-123.4554 488,-101 512.3047,-92.6499 535.0206,-74.3092 550.9958,-58.9247\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"553.6646,-61.2062 558.2741,-51.6666 548.7217,-56.2496 553.6646,-61.2062\"/>\n</g>\n<!-- h1 -->\n<g id=\"node6\" class=\"node\">\n<title>h1</title>\n<ellipse fill=\"#ffff00\" stroke=\"#ffff00\" cx=\"737\" cy=\"-34\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"737\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h1</text>\n</g>\n<!-- dense_features&#45;&gt;h1 -->\n<g id=\"edge5\" class=\"edge\">\n<title>dense_features&#45;&gt;h1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M639.2637,-34C659.4042,-34 679.5447,-34 699.6852,-34\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"699.8935,-37.5001 709.8934,-34 699.8934,-30.5001 699.8935,-37.5001\"/>\n</g>\n<!-- h2 -->\n<g id=\"node7\" class=\"node\">\n<title>h2</title>\n<ellipse fill=\"#ffff00\" stroke=\"#ffff00\" cx=\"908\" cy=\"-34\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"908\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">h2</text>\n</g>\n<!-- h1&#45;&gt;h2 -->\n<g id=\"edge6\" class=\"edge\">\n<title>h1&#45;&gt;h2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M764.0527,-34C799.6025,-34 835.1522,-34 870.7019,-34\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"870.7288,-37.5001 880.7287,-34 870.7287,-30.5001 870.7288,-37.5001\"/>\n</g>\n<!-- weight -->\n<g id=\"node8\" class=\"node\">\n<title>weight</title>\n<ellipse fill=\"#00ff00\" stroke=\"#00ff00\" cx=\"1035\" cy=\"-34\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"1035\" y=\"-30.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">weight</text>\n</g>\n<!-- h2&#45;&gt;weight -->\n<g id=\"edge7\" class=\"edge\">\n<title>h2&#45;&gt;weight</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M935.2852,-34C952.8679,-34 970.4507,-34 988.0335,-34\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"988.386,-37.5001 998.386,-34 988.3859,-30.5001 988.386,-37.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "usK1D3mRr-td",
        "outputId": "61e1ff1c-4f36-42b2-864d-8a72e9d62e96"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model=model, to_file=\"dnn_model.png\", show_shapes=False, rankdir=\"LR\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-3da8814dd371>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m tf.keras.utils.plot_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     model=model, to_file=\"dnn_model.png\", show_shapes=False, rankdir=\"LR\")\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAAHKwpJvhHi"
      },
      "source": [
        "### run and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxZ2WIVGGCeG"
      },
      "source": [
        "TRAIN_BATCH_SIZE = 32\n",
        "NUM_TRAIN_EXAMPLES = 10000 * 5  # training dataset repeats, it'll wrap around\n",
        "NUM_EVALS = 5  # how many times to evaluate\n",
        "# Enough to get a reasonable sample, but not so much that it slows down\n",
        "NUM_EVAL_EXAMPLES = 10000\n",
        "\n",
        "trainds = load_dataset(\n",
        "    pattern     =\"train*\",\n",
        "    batch_size  =TRAIN_BATCH_SIZE,\n",
        "    mode        ='train')\n",
        "\n",
        "evalds = load_dataset(\n",
        "    pattern     =\"eval*\",\n",
        "    batch_size  =1000,\n",
        "    mode        ='eval').take(count=NUM_EVAL_EXAMPLES // 1000)\n",
        "\n",
        "steps_per_epoch = NUM_TRAIN_EXAMPLES // (TRAIN_BATCH_SIZE * NUM_EVALS)\n",
        "\n",
        "logdir = os.path.join( \"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") )\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard( log_dir=logdir, histogram_freq=1)\n",
        "\n",
        "history = model.fit(\n",
        "    trainds,\n",
        "    validation_data =evalds,\n",
        "    epochs          =NUM_EVALS,\n",
        "    steps_per_epoch =steps_per_epoch,\n",
        "    callbacks       =[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi14Y7w7wUHf"
      },
      "source": [
        "### visualize loss curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfPE8nOKwYHI"
      },
      "source": [
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "nrows = 1\n",
        "ncols = 2\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "for idx, key in enumerate([\"loss\", \"rmse\"]):\n",
        "    ax = fig.add_subplot(nrows, ncols, idx+1)\n",
        "    plt.plot(history.history[key])\n",
        "    plt.plot(history.history[\"val_{}\".format(key)])\n",
        "    plt.title(\"model {}\".format(key))\n",
        "    plt.ylabel(key)\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdPlmOiEwZ3g"
      },
      "source": [
        "### save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIJLl9XgwfCi"
      },
      "source": [
        "OUTPUT_DIR = \"babyweight_trained\"\n",
        "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
        "\n",
        "EXPORT_PATH = os.path.join( OUTPUT_DIR, datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n",
        "\n",
        "tf.saved_model.save( obj=model, export_dir=EXPORT_PATH)  # with default serving function\n",
        "\n",
        "print(\"Exported trained model to {}\".format(EXPORT_PATH))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}